{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background: linear-gradient(to right, #ff6b6b, #4ecdc4); \n",
    "           color: white; \n",
    "           padding: 20px; \n",
    "           border-radius: 10px; \n",
    "           text-align: center; \n",
    "           font-family: Arial, sans-serif; \n",
    "           text-shadow: 2px 2px 4px rgba(0,0,0,0.5);\">\n",
    "    DeepSeek-R1 with Amazon Bedrock \n",
    "</h1>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prerequisites\n",
    "\n",
    "- An AWS account with access to Amazon Bedrock\n",
    "- An AWS IAM Role with permissions for Bedrock and S3, following these instructions: [Create a service role for model import](https://docs.aws.amazon.com/bedrock/latest/userguide/model-import-iam-role.html)\n",
    "- An Amazon S3 bucket prepared to store the custom model\n",
    "- Sufficient local storage space (at least 17GB for 8B and 135GB for 70B models)\n",
    "\n",
    "## Step 1: Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -U huggingface_hub -q\n",
    "!pip install boto3 --upgrade -q"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Configure parameters"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Defaults\n",
    "default_region = 'us-east-1'\n",
    "default_repository_id = 'deepseek-ai/DeepSeek-R1-Distill-Llama-8B'\n",
    "default_s3_root_folder = '/'\n",
    "default_s3_bucket_name = 'bedrock-imported-models'\n",
    "default_import_role_name = 'AmazonBedrockModelImportRole'\n",
    "default_import_policy_name = 'AmazonBedrockModelImportPolicy'\n",
    "\n",
    "# Get parameters from user\n",
    "repository_id = input(f\"Enter Hugging Face repository ID ['{default_repository_id}']: \") or default_repository_id\n",
    "\n",
    "# AWS Region\n",
    "aws_region = input(f\"Enter the AWS region: ['us-east-1']: \") or default_region\n",
    "\n",
    "# The name of the model import role. Please make sure it has sufficient permission as listed in the prerequisites!\n",
    "import_role_name = input(\"Enter the IAM role name for the model import [Leave empty to create a new role]\") or None\n",
    "\n",
    "# The Amazon S3 bucket name and root folder for the model file upload \n",
    "s3_bucket_name = input('Enter the S3 bucket name [Leave empty to create a new bucket]') or None\n",
    "s3_root_folder = input(f\"Enter the S3 root prefix ['{default_s3_root_folder}']\") or default_s3_root_folder\n",
    "\n",
    "print('Configuration:')\n",
    "print(f\"- HF Repository ID: {repository_id}\")\n",
    "print(f\"- Import role ARN: {import_role_name or 'Create a new IAM role'}\")\n",
    "print(f\"- S3 bucket: {s3_bucket_name or 'Create a new S3 bucket'}\")\n",
    "print(f\"- S3 root folder: {s3_root_folder}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Create new IAM Role and S3 Bucket if required"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create a random resource name postfix\n",
    "postfix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "\n",
    "def get_aws_account_id():\n",
    "    sts_client = boto3.client('sts')\n",
    "    return sts_client.get_caller_identity()['Account']\n",
    "\n",
    "def get_or_create_role(role_name):\n",
    "    iam_client = boto3.client('iam')\n",
    "    \n",
    "    if not role_name:\n",
    "        print('Creating new IAM role...')\n",
    "        \n",
    "        account_id = get_aws_account_id()\n",
    "        role_name = f\"{default_import_role_name}-{postfix}\"\n",
    "       \n",
    "        trust_policy = {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [{\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": { \"Service\": \"bedrock.amazonaws.com\" },\n",
    "                \"Action\": \"sts:AssumeRole\",\n",
    "                \"Condition\": {\n",
    "                    \"StringEquals\": { \"aws:SourceAccount\": account_id },\n",
    "                    \"ArnEquals\": {\n",
    "                        \"aws:SourceArn\": f\"arn:aws:bedrock:{aws_region}:{account_id}:model-import-job/*\"\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        inline_policy = {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [{\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\n",
    "                        \"s3:GetObject\",\n",
    "                        \"s3:ListBucket\"\n",
    "                    ],\n",
    "                    \"Resource\": [\n",
    "                        s3_bucket_arn,\n",
    "                        f\"{s3_bucket_arn}/*\"\n",
    "                    ],\n",
    "                    \"Condition\": {\n",
    "                        \"StringEquals\": {\n",
    "                            \"aws:ResourceAccount\": account_id\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            role = iam_client.create_role(\n",
    "                RoleName=role_name,\n",
    "                AssumeRolePolicyDocument=json.dumps(trust_policy)\n",
    "            )\n",
    "\n",
    "            iam_client.put_role_policy(\n",
    "                RoleName=role_name,\n",
    "                PolicyName=f\"{default_import_policy_name}\",\n",
    "                PolicyDocument=json.dumps(inline_policy)\n",
    "            )\n",
    "            \n",
    "            print(f\"Successfully created IAM role: {role_name}\")\n",
    "        except ClientError as e:\n",
    "            print(f\"Error creating IAM role: {e}\")\n",
    "            exit(1)\n",
    "    else:\n",
    "        print(f\"Checking IAM role: {role_name}\")\n",
    "        try:\n",
    "            role = iam_client.get_role(RoleName=role_name)\n",
    "            print('Found existing role.')\n",
    "        except ClientError as e:\n",
    "            print(f\"Error retrieving S3 bucket: {e}\")\n",
    "            exit(1)\n",
    "            \n",
    "    return role[\"Role\"]\n",
    "\n",
    "def get_or_create_bucket(bucket_name):\n",
    "    s3_client = boto3.client('s3', region_name=aws_region)\n",
    "    \n",
    "    if not bucket_name:\n",
    "        print(f\"Creating new S3 bucket...\")\n",
    "        \n",
    "        bucket_name = f\"{default_s3_bucket_name}-{postfix}\"\n",
    "        \n",
    "        try:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "            \n",
    "            # Wait until bucket exists\n",
    "            waiter = s3_client.get_waiter('bucket_exists')\n",
    "            waiter.wait(\n",
    "                Bucket=bucket_name,\n",
    "                WaiterConfig={\n",
    "                    'Delay': 5,\n",
    "                    'MaxAttempts': 20\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print(f\"Successfully created S3 bucket: {bucket_name}\")\n",
    "            return bucket_name\n",
    "            \n",
    "        except ClientError as e:\n",
    "            print(f\"Error creating S3 bucket: {e}\")\n",
    "            exit(1)\n",
    "    else:\n",
    "        print(f\"Checking S3 bucket: {bucket_name}\")\n",
    "        try:\n",
    "            bucket = s3_client.head_bucket(Bucket=bucket_name)\n",
    "            print('Found existing bucket')\n",
    "        except ClientError as e:\n",
    "            print(f\"Error retrieving IAM role: {e}\")\n",
    "            exit(1)\n",
    "\n",
    "import_role = get_or_create_role(import_role_name)\n",
    "import_role_arn = import_role[\"Arn\"]\n",
    "\n",
    "s3_bucket = get_or_create_bucket(s3_bucket_name)\n",
    "s3_bucket_arn = f\"arn:aws:s3:::{s3_bucket_name}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Download and deploy the model\n",
    "## Step 1: Download the weights from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = snapshot_download(repository_id)\n",
    "print(f\"Model downloaded to: {local_dir}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Upload the weights to Amazon S3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3_folder = repository_id if s3_root_folder == '/' else f'{s3_root_folder}/{repository_id}'\n",
    "s3_folder_uri = f\"s3://{s3_bucket_name}/{s3_folder}\"\n",
    "\n",
    "def file_exists_in_s3(bucket_name, s3_key):\n",
    "    return s3.list_objects_v2(Bucket=bucket_name, Prefix=s3_key)['KeyCount'] > 0\n",
    "\n",
    "def upload_to_s3():\n",
    "    for root, _, files in os.walk(local_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(file_path, local_dir)\n",
    "            s3_key = f\"{s3_folder}/{relative_path}\"\n",
    "            \n",
    "            if file_exists_in_s3(s3_bucket_name, s3_key):\n",
    "                print(f\"Skipping existing file: s3://{s3_bucket_name}/{s3_key}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Uploading: {file_path} to s3://{s3_bucket_name}/{s3_key}\")\n",
    "            s3.upload_file(file_path, s3_bucket_name, s3_key)\n",
    "\n",
    "print('Uploading model files to S3...')\n",
    "\n",
    "upload_to_s3()\n",
    "\n",
    "print(f\"Successfully uploaded model files to {s3_folder_uri}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Import the model\n",
    "### 3.1: Import the model to Amazon Bedrock "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "bedrock = boto3.client('bedrock', region_name=aws_region)\n",
    "model_name = repository_id.split('/')[-1].replace('.', '-').replace('_', '-')\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "job_name = f'{model_name}-{timestamp}'\n",
    "\n",
    "print(f\"Starting model import job: {job_name}\")\n",
    "\n",
    "# Create the model import job\n",
    "response = bedrock.create_model_import_job(\n",
    "    jobName=job_name,\n",
    "    importedModelName=model_name,\n",
    "    roleArn=import_role_arn,\n",
    "    modelDataSource={'s3DataSource': {'s3Uri': s3_folder_uri}}\n",
    ")\n",
    "\n",
    "print(f\"Model import job started\")\n",
    "\n",
    "job_arn = response['jobArn']\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2: Monitor the import job status"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "print(f\"Checking status of import job: {job_name}\")\n",
    "while True:\n",
    "    response = bedrock.get_model_import_job(jobIdentifier=job_arn)\n",
    "    status = response['status']\n",
    "    if status == 'Failed':\n",
    "        print('Model import failed!')\n",
    "        \n",
    "        failure_message = response['failureMessage']\n",
    "        print(f\"Reason: {failure_message}\")\n",
    "        break\n",
    "    elif status == 'Completed':\n",
    "        print('Model import complete.')\n",
    "        \n",
    "        model_id = response['importedModelArn']\n",
    "        print(f\"Imported model ID: {model_id}\")\n",
    "        break\n",
    "    else:\n",
    "        print('Importing...')\n",
    "\n",
    "    time.sleep(60)  # Check every 60 seconds\n",
    "    \n",
    "model_arn = response['importedModelArn']\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3: If necessary, wait some more time to make sure the model has been initialized"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wait for 5 minutes for model initialization \n",
    "print('Waiting 5 minutes for model initialization...')\n",
    "\n",
    "for i in range(5, 0, -1):\n",
    "    print(f'{i} minute{\"s\" if i > 1 else \"\"}...')\n",
    "    time.sleep(60)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Test the model\n",
    "\n",
    "## Step 1: Define the prompt "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompt = \"Once upon a time \"",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Invoke the model\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from botocore.config import Config\n",
    "\n",
    "def invoke_model(model, message):\n",
    "    config = Config(\n",
    "        retries={\n",
    "            'total_max_attempts': 10, \n",
    "            'mode': 'standard'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    session = boto3.session.Session()\n",
    "    br_runtime = session.client('bedrock-runtime', region_name=aws_region, config=config)\n",
    "        \n",
    "    try:\n",
    "        invoke_response = br_runtime.invoke_model(\n",
    "            modelId=model, \n",
    "            body=json.dumps({'prompt': prompt}) \n",
    "        )\n",
    "        result = invoke_response[\"body\"] = json.loads(invoke_response[\"body\"].read().decode(\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(e.__repr__())\n",
    "\n",
    "    return result\n",
    "\n",
    "response = invoke_model(model=model_arn, message=prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Display the response"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from IPython import display\n",
    "display.Markdown(response['generation'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
